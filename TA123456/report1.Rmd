---
title: "First Assignment"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(ggplot2)
library(readr)
library(dotwhisker)
library(glmnet)
set.seed(100L)
myData=read_csv("w_logret_3automanu.csv",col_names=FALSE)
names(myData)=c("Toyota","Ford","GM") 
```

## Simple regression and it's plots
```{r}
myFit1=lm(GM~.,data=myData)
par(mfrow=c(2,3))
plot(myFit1,which=1:6,ask=FALSE,id.n=3)
```

- the labelled point of the first three and the last three are different

- symbol : and * is different (see ?formula)

## The influence of intercept
```{r}
myFit2=update(myFit1,.~.-1)

dwplot(list(myFit1,myFit2))+
    theme_bw()+
    geom_vline(xintercept = 0,colour="green",linetype=2)
confint(myFit1)
```

## remove influential points
```{r}
tmp= 1:709 %in% 402
myFit3=update(myFit1,subset=!tmp)
par(mfrow=c(2,3))
plot(myFit3,which=1:6,ask=FALSE,id.n=3)
dwplot(list(myFit1,myFit3))+
    theme_bw()+
    geom_vline(xintercept = 0,colour="green",linetype=2)
```
```{r}
tmp=1:709 %in% c(402,
                 334,644)
myFit4=update(myFit1,subset=!tmp)
par(mfrow=c(2,3))
plot(myFit4,which=1:6,ask=FALSE,id.n=3)
dwplot(list(myFit3,myFit4))+
    theme_bw()+
    geom_vline(xintercept = 0,colour="green",linetype=2)
```

## the wrong way:

```{r}
myData=read.csv("w_logret_3automanu.csv",header = FALSE)
names(myData)=c("Toyota","Ford","GM")
myData1=myData[-402,]
wrong1=lm(GM~.,data=myData1)
par(mfrow=c(2,3))
plot(wrong1,which=1:6,ask=FALSE)
```

now the 3 biggest cook's D is 334, 643, 311. But
```{r}
wrong1$residuals[c(334,643,311)]
wrong1$residuals[c(335,644,311)]
```

it is because of the behavior of rownames of myData1. So how to solve it?

## First method: rename the row

```{r}
rownames(myData1)=1:nrow(myData1)
```

## Second method: use read_csv as we did (recommand)

```{r}
myData=read_csv("w_logret_3automanu.csv",col_names=FALSE)
names(myData)=c("Toyota","Ford","GM")
myData1=myData[-402,]
right1=lm(GM~.,data=myData1)
right1$residuals[c(334,643,311)]
```

# Prediction

First we plot the confident interval of myFit1

```{r}
myFit5=update(myFit1,.~Ford-1)
tmpData=myData
tmpData[,c("lc","uc")]=predict(myFit5,myData,level=0.95,interval="confidence")[,c(2,3)]
tmpData[,c("lp","up")]=predict(myFit5,myData,level=0.95,interval="prediction")[,c(2,3)]

ggplot(data=tmpData)+
  geom_line(aes(x=Ford,y=lc),color="red",linetype=2)+
  geom_line(aes(x=Ford,y=uc),color="red",linetype=2)+
  geom_line(aes(x=Ford,y=lp),color="green",linetype=2)+
  geom_line(aes(x=Ford,y=up),color="green",linetype=2)+
  geom_abline(intercept = 0,slope = myFit5$coefficients[["Ford"]])+
  ylab("GM")
```

Next, we want to do better

## Feature engineering

```{r}
for(i in 1:4){
  myData[,paste("featureT",i,sep="")]=factor(1*(myData$Toyota>quantile(abs(myData$Toyota),i/5)))
}

for(i in 1:4){
  myData[,paste("featureF",i,sep="")]=factor(1*(myData$Ford>quantile(abs(myData$Ford),i/5)))
}
```

## Split the data to obtain training set and testing set

```{r}
inT=sample(1:nrow(myData),600)
training=myData[inT,]
testing=myData[-inT,]
```

## The MSE of univariate regression and new regression 

```{r}
pFit1=lm(GM~(.)^2,training)
sum((predict(pFit1,testing)-testing$GM)^2)
pFit2=lm(GM~Ford,training)
sum((predict(pFit2,testing)-testing$GM)^2)
```

The new model behave even worse! It overfits!! To overcome overfitting, we regularize the regeression by the LASSO.

$$
min \frac{1}{2n}\|y-X\beta\|^2+\lambda \sum^p_{i=1} |\beta_i|
$$

```{r}
tmp=model.matrix(GM~(.)^2,training)
tmp=as.data.frame(tmp)
glmFit=glmnet(as.matrix(tmp),as.matrix(training$GM),family="gaussian")
coef(glmFit,s=0.01)
plot(glmFit)
```

## Determine $\lambda$ by cross validation

```{r}
glmFit2=cv.glmnet(as.matrix(tmp),
                  as.matrix(training$GM),
                  family="gaussian",
                  nfolds=10,
                  lambda=c(1e-5,0.0001,0.001,0.01,0.1,1,10,100))

plot(glmFit2)
coef(glmFit,s=1e-4)
myPre=predict.glmnet(glmFit,model.matrix(GM~(.)^2,testing),s=1e-4)
sum((myPre-testing$GM)^2)
```
